---
title: Greedy Strategy
author: Lorenzo Drumond
date: 2023-11-20T17:15:38
last: 2023-11-20T18:02:20
zk_id: 20231120171538
tags: #strategy #statistics #greedy #exploration #regret #tradeoff #math #medium #bandits #multi_armed #exploitation
---


# Greedy Strategy
A greedy strategy consists of always taking the decision that seems to be the best with respect to the current knowledge: full exploitation, no exploration. If knowledge is not accurate, we may remain stuck in sub-optimal choices.

## Example
3-armed Bernoulli bandit:
- $p_1 = 0.3$
- $p_2 = 0.7$
- $p_3 = 0.8

We are assuming a prior knowledge for each of the $p_i$'s set to 0.5. The $p_i$'s estimate at time $t$ is:
```latex
e_i^t
```

therefore: $e_1^0 = 0.5, e_2^0 = 0.5, e_3^0 = 0.5$

At this stage the greedy agent picks a random action: $c_2$, and $r_t = 1$. We can thus update our expectation for choice 2:
$e_1^1 = e_1^0 = 0.5, e_2^1 = (e_2^0 + r_1)/2 = 0.75, e_3^1 = e_3^0 = 0.5$

# References
- https://towardsdatascience.com/the-exploration-exploitation-dilemma-f5622fbe1e82
- [[exploration-vs-exploitation]]
- [[test]]
- [[test]]

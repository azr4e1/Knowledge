---
title: e-greedy
author: Lorenzo Drumond
date: 2023-11-27T16:09:10
last: 2023-11-27T16:11:11
zk_id: e98af0588a65eb8ba68fa194dad77136
tags: #strategy #regret #bandits #exploitation #medium #exploration #greedy #statistics #math #tradeoff #multi_armed
---


# e-greedy
This strategy introduces exploration:

  The idea is to take either the most optimal (known) choice with probability $(1-e)$, or a random choice with probability $e$.

Therefore we can balance how much exploration we want by tuning the $e$ parameter: 0 = full exploitation, 1 = full exploration

# References
- [[exploration-vs-exploitation]]
